{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjnt9PkAQKUe",
        "outputId": "ad2a2582-06a8-4c09-8860-ff8f8724087c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/lingfengzhang/pediatric-polymicrogyria-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 709M/709M [00:11<00:00, 65.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"lingfengzhang/pediatric-polymicrogyria-mri-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz7x2zXVQQxv",
        "outputId": "78de5a1e-2ce4-4b22-cf23-9a6158e1d5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision matplotlib pillow scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEqkqvvfQfxL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import models\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2OHkG-CQjD4"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define preprocessing transformations for test data (only resizing and normalization)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "    transforms.ToTensor(),          # Convert images to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Define transformations for training data (include augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomVerticalFlip(),    # Randomly flip images vertically\n",
        "    transforms.RandomRotation(30),      # Rotate images by up to 30 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Adjust brightness/contrast\n",
        "    transforms.Resize((224, 224)),      # Resize to 224x224 after augmentations\n",
        "    transforms.ToTensor(),              # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZQBo9nvWkTr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class PolymicrogyriaDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Open image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbMn9zTbWoiU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "85c360b3-fb58-482d-c9b6-09c7835ac790"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_paths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d4d61712ebec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Dataset objects for train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolymicrogyriaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolymicrogyriaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_paths' is not defined"
          ]
        }
      ],
      "source": [
        "# Create Dataset objects for train and test sets\n",
        "train_dataset = PolymicrogyriaDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PolymicrogyriaDataset(test_paths, test_labels, transform=test_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr-yh9zDWsUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "fefe4ad8-c532-498a-de46-cf66ca5e9b2d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-efa9b22cd17b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create DataLoader objects for batching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoader objects for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SNdNhOt4WwVz",
        "outputId": "1455f0cc-d59d-41ad-ef19-fc0e05cd0d6c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ef7a81840b5c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verify dataset and dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of batches in train loader: {len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of batches in test loader: {len(test_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Visualize a batch of images to ensure transformations are applied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "# Verify dataset and dataloader\n",
        "print(f\"Number of batches in train loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in test loader: {len(test_loader)}\")\n",
        "\n",
        "# Visualize a batch of images to ensure transformations are applied\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Grab a batch of data\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Convert tensor images back to numpy format for display\n",
        "images = images.numpy().transpose((0, 2, 3, 1))  # Convert from (N, C, H, W) to (N, H, W, C)\n",
        "\n",
        "# Plot a few images\n",
        "fig, axes = plt.subplots(1, 5, figsize=(12, 12))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(images[i])\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z_z4aZbValC",
        "outputId": "c92d12cc-0e1b-49ae-84a8-a7c7769e7b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing PPMR directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGControlsEditedDec2021\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGstudycaseslabelled\n",
            "Total images found: 15056\n",
            "Train set: 12044, Test set: 3012\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define base dataset path\n",
        "base_path = '/root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2'\n",
        "ppmr_path = os.path.join(base_path, 'PPMR')\n",
        "\n",
        "# Collect image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Define a mapping for directories\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",  # Healthy cases\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"  # PMG cases\n",
        "}\n",
        "\n",
        "if os.path.exists(ppmr_path) and os.path.isdir(ppmr_path):\n",
        "    print(f\"Processing PPMR directory: {ppmr_path}\")\n",
        "    for main_dir, label_name in main_dir_labels.items():\n",
        "        main_dir_path = os.path.join(ppmr_path, main_dir)\n",
        "\n",
        "        if os.path.isdir(main_dir_path):\n",
        "            print(f\"Processing main directory: {main_dir_path}\")\n",
        "            for patient_dir in os.listdir(main_dir_path):\n",
        "                patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "                if os.path.isdir(patient_path):\n",
        "                    for sub_dir in os.listdir(patient_path):\n",
        "                        sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                        if os.path.isdir(sub_dir_path):\n",
        "                            for fname in os.listdir(sub_dir_path):\n",
        "                                if fname.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                                    file_path = os.path.join(sub_dir_path, fname)\n",
        "                                    image_paths.append(file_path)\n",
        "                                    labels.append(label_name)\n",
        "        else:\n",
        "            print(f\"Main directory not found: {main_dir_path}\")\n",
        "else:\n",
        "    print(\"PPMR directory not found.\")\n",
        "\n",
        "# Check if any files were found\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "\n",
        "# Label encoding\n",
        "if image_paths:\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Split dataset into train and test\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    print(f\"Train set: {len(train_paths)}, Test set: {len(test_paths)}\")\n",
        "else:\n",
        "    print(\"No images found. Ensure the directory structure and file extensions are correct.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class cDCMLoss(nn.Module):\n",
        "    def __init__(self, margin=5.0, alpha=1.0):\n",
        "        super(cDCMLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, outputs, labels, center):\n",
        "        distances = torch.norm(outputs - center, dim=1)\n",
        "        normal_loss = (1 - labels) * distances\n",
        "        anomaly_loss = (\n",
        "            labels * (torch.clamp(self.margin - distances, min=0) +\n",
        "                      1 / (1 + torch.exp(distances - self.margin)))\n",
        "        )\n",
        "        loss = torch.mean(normal_loss + self.alpha * anomaly_loss)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "iSSIae-VWXKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "1701254a-ee07-4a82-bbde-6f05bbbbe176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c97987c15e6b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mcDCMLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcDCMLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "def train_cdcmloss(model, data, labels, n_folds=5, margin=5.0, alpha=1.0):\n",
        "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
        "        print(f\"Fold {fold + 1}/{n_folds}\")\n",
        "\n",
        "        train_data = data[train_idx]\n",
        "        train_labels = labels[train_idx]\n",
        "        val_data = data[val_idx]\n",
        "        val_labels = labels[val_idx]\n",
        "\n",
        "        # Define model, optimizer, and scheduler\n",
        "        model = model.to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "        criterion = cDCMLoss(margin=margin, alpha=alpha)\n",
        "        center = torch.zeros((1, model.fc.out_features)).to(device)  # Adjust for model output\n",
        "\n",
        "        # Training Loop\n",
        "        for epoch in range(epochs):  # Apply early stopping as needed\n",
        "            model.train()\n",
        "            # Training logic here\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        # Evaluate AUCROC, recall, F2, etc.\n",
        "        results.append((fold_aucroc, fold_recall, fold_f2))\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "g61_YwAuWfyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, fbeta_score, roc_auc_score\n",
        "\n",
        "def evaluate_model(model, data_loader, labels):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs.to(device))\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    recall = recall_score(true_labels, predictions, average=\"binary\")\n",
        "    f2 = fbeta_score(true_labels, predictions, beta=2, average=\"binary\")\n",
        "    aucroc = roc_auc_score(true_labels, predictions)\n",
        "    return recall, f2, aucroc\n"
      ],
      "metadata": {
        "id": "ASc7TTeiWoZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50, MobileNetV2, EfficientNetB0\n",
        "\n",
        "def dilated_conv_block(x, filters, kernel_size, dilation_rate):\n",
        "    x = layers.Conv2D(filters, kernel_size, dilation_rate=dilation_rate, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def squeeze_and_excitation_block(x, reduction_ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // reduction_ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    x = layers.Multiply()([x, se])\n",
        "    return x\n",
        "\n",
        "def custom_cnn(input_shape=(224, 224, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # First block: Dilated Convolutions\n",
        "    x = dilated_conv_block(inputs, 32, (3, 3), dilation_rate=1)\n",
        "    x = dilated_conv_block(x, 64, (3, 3), dilation_rate=2)\n",
        "\n",
        "    # Squeeze-and-Excitation Block\n",
        "    x = squeeze_and_excitation_block(x)\n",
        "\n",
        "    # More layers or blocks as required\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-AXPP3OFW_kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def integrate_model(base_model, input_shape=(224, 224, 3)):\n",
        "    # Freeze the base model to use it as a feature extractor\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "\n",
        "    # Add custom CNN layers after the base model\n",
        "    x = dilated_conv_block(x, 128, (3, 3), dilation_rate=1)\n",
        "    x = squeeze_and_excitation_block(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# ResNet50\n",
        "resnet50_model = integrate_model(ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
        "\n",
        "# MobileNetV2\n",
        "mobilenetv2_model = integrate_model(MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
        "\n",
        "# EfficientNetB0\n",
        "efficientnetb0_model = integrate_model(EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XHu0UiqXC-s",
        "outputId": "b1dffc89-5778-4746-da9b-825b1206c61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define EarlyStopping callback to stop training if validation loss doesn't decrease\n",
        "# after 4,500 iterations. Set patience in terms of epochs.\n",
        "\n",
        "# Assuming you have a fixed batch size and you're interested in the number of iterations\n",
        "batch_size = 32\n",
        "max_iterations = 4500\n",
        "\n",
        "# Set patience based on the number of iterations per epoch\n",
        "# For example, if your dataset has 1000 samples, you would get 1000 // 32 = ~31 iterations per epoch.\n",
        "# To hit 4500 iterations, we calculate the number of epochs required:\n",
        "iterations_per_epoch = len(X_train) // batch_size  # This should be the number of iterations per epoch\n",
        "epochs_until_stop = max_iterations // iterations_per_epoch  # This gives you the number of epochs for 4500 iterations\n",
        "\n",
        "# EarlyStopping with patience based on epochs\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=epochs_until_stop, restore_best_weights=True)\n",
        "\n",
        "# Now let's modify the training loop to use early stopping\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}\")\n",
        "\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Create data generators\n",
        "    train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "    val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
        "\n",
        "    # Choose a model (ResNet50, MobileNetV2, or EfficientNetB0)\n",
        "    model = resnet50_model  # Example with ResNet50, you can switch between models\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with EarlyStopping\n",
        "    model.fit(train_generator, validation_data=val_generator, epochs=400, callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "    print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "X8e8gFY7XKxC",
        "outputId": "e6b23f36-2997-4c89-c23d-48c12f4d8979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-963fff8a97a1>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# For example, if your dataset has 1000 samples, you would get 1000 // 32 = ~31 iterations per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# To hit 4500 iterations, we calculate the number of epochs required:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0miterations_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m  \u001b[0;31m# This should be the number of iterations per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mepochs_until_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iterations\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0miterations_per_epoch\u001b[0m  \u001b[0;31m# This gives you the number of epochs for 4500 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XczmcyEWM52",
        "outputId": "936632cf-d228-46bf-bfca-ed237ad479f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NKUT'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 164 (delta 0), reused 0 (delta 0), pack-reused 161 (from 1)\u001b[K\n",
            "Receiving objects: 100% (164/164), 1.05 MiB | 3.03 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nkicsl/NKUT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnu-P9dYXf1E",
        "outputId": "27a710fa-410e-43e2-8724-3934e66b5e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NKUT\n"
          ]
        }
      ],
      "source": [
        "%cd NKUT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQngcRTJXiLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9971696-43db-49ee-f5a4-8456bc268568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0J3UfkNXpDh",
        "outputId": "ae61362a-22b7-4fb7-9a1f-fc8a5f6081fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import Recall\n",
        "\n",
        "# Define base dataset path\n",
        "base_path = '/root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2'\n",
        "ppmr_path = os.path.join(base_path, 'PPMR')\n",
        "\n",
        "# Collect image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Define a mapping for directories\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",  # Healthy cases\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"  # PMG cases\n",
        "}\n",
        "\n",
        "if os.path.exists(ppmr_path) and os.path.isdir(ppmr_path):\n",
        "    print(f\"Processing PPMR directory: {ppmr_path}\")\n",
        "    for main_dir, label_name in main_dir_labels.items():\n",
        "        main_dir_path = os.path.join(ppmr_path, main_dir)\n",
        "\n",
        "        if os.path.isdir(main_dir_path):\n",
        "            print(f\"Processing main directory: {main_dir_path}\")\n",
        "            for patient_dir in os.listdir(main_dir_path):\n",
        "                patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "                if os.path.isdir(patient_path):\n",
        "                    for sub_dir in os.listdir(patient_path):\n",
        "                        sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                        if os.path.isdir(sub_dir_path):\n",
        "                            for fname in os.listdir(sub_dir_path):\n",
        "                                if fname.endswith(('.jpg', '.png', '.jpeg')):  # Image extensions\n",
        "                                    file_path = os.path.join(sub_dir_path, fname)\n",
        "                                    image_paths.append(file_path)\n",
        "                                    labels.append(label_name)\n",
        "        else:\n",
        "            print(f\"Main directory not found: {main_dir_path}\")\n",
        "else:\n",
        "    print(\"PPMR directory not found.\")\n",
        "\n",
        "# Check if any files were found\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "\n",
        "# Label encoding\n",
        "if image_paths:\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Split dataset into train and test\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    print(f\"Train set: {len(train_paths)}, Test set: {len(test_paths)}\")\n",
        "else:\n",
        "    print(\"No images found. Ensure the directory structure and file extensions are correct.\")\n",
        "\n",
        "# Data Generator for Loading and Preprocessing Images\n",
        "def image_generator(image_paths, labels, batch_size=32, target_size=(224, 224)):\n",
        "    while True:\n",
        "        for start in range(0, len(image_paths), batch_size):\n",
        "            end = min(start + batch_size, len(image_paths))\n",
        "            batch_paths = image_paths[start:end]\n",
        "            batch_labels = labels[start:end]\n",
        "\n",
        "            # Load and preprocess images\n",
        "            images = []\n",
        "            for path in batch_paths:\n",
        "                img = load_img(path, target_size=target_size)\n",
        "                img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "                images.append(img_array)\n",
        "\n",
        "            yield np.array(images), np.array(batch_labels)\n",
        "\n",
        "# Create train and validation generators\n",
        "train_generator = image_generator(train_paths, train_labels, batch_size=32)\n",
        "val_generator = image_generator(test_paths, test_labels, batch_size=32)\n",
        "\n",
        "# Define Model (e.g., ResNet50, MobileNetV2, or EfficientNetB0)\n",
        "def build_model(base_model):\n",
        "    base_model.trainable = False  # Freeze the base model layers\n",
        "\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "\n",
        "    # Add custom CNN layers\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)  # Binary classification: 1 output neuron with sigmoid\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Choose the pre-trained model (ResNet50 as an example)\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Build the model\n",
        "model = build_model(base_model)\n",
        "\n",
        "# Compile the model with recall as a metric (using binary_crossentropy)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall()])  # For binary classification\n",
        "\n",
        "# Define EarlyStopping callback (patience in terms of epochs)\n",
        "batch_size = 32\n",
        "max_iterations = 4500\n",
        "iterations_per_epoch = len(train_paths) // batch_size\n",
        "epochs_until_stop = max_iterations // iterations_per_epoch\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=epochs_until_stop, restore_best_weights=True)\n",
        "\n",
        "# Train the model with EarlyStopping\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=len(train_paths) // batch_size,  # Steps per epoch\n",
        "    validation_steps=len(test_paths) // batch_size,  # Validation steps\n",
        "    epochs=400,  # Maximum number of epochs\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model using Recall\n",
        "val_loss, val_recall = model.evaluate(val_generator, steps=len(test_paths) // batch_size)\n",
        "print(f\"Validation Recall: {val_recall * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "NNvyjx3ecZmj",
        "outputId": "1a54dd59-ae8b-401f-ebc7-efab2bcd6237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing PPMR directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGControlsEditedDec2021\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGstudycaseslabelled\n",
            "Total images found: 15056\n",
            "Train set: 12044, Test set: 3012\n",
            "Epoch 1/400\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 224ms/step - loss: 0.5811 - recall: 0.2294 - val_loss: 0.1928 - val_recall: 0.8499\n",
            "Epoch 2/400\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 215ms/step - loss: 0.1754 - recall: 0.8538 - val_loss: 0.1545 - val_recall: 0.8115\n",
            "Epoch 3/400\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 199ms/step - loss: 0.1116 - recall: 0.9118 - val_loss: 0.0708 - val_recall: 0.9200\n",
            "Epoch 4/400\n",
            "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 198ms/step - loss: 0.0782 - recall: 0.9368 - val_loss: 0.0519 - val_recall: 0.9400\n",
            "Epoch 5/400\n",
            "\u001b[1m259/376\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - loss: 0.0632 - recall: 0.9524"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1a8e0bba27cc>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Train the model with EarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import Recall\n",
        "\n",
        "# Define base dataset path\n",
        "base_path = '/root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2'\n",
        "ppmr_path = os.path.join(base_path, 'PPMR')\n",
        "\n",
        "# Collect image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Define a mapping for directories\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",  # Healthy cases\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"  # PMG cases\n",
        "}\n",
        "\n",
        "if os.path.exists(ppmr_path) and os.path.isdir(ppmr_path):\n",
        "    print(f\"Processing PPMR directory: {ppmr_path}\")\n",
        "    for main_dir, label_name in main_dir_labels.items():\n",
        "        main_dir_path = os.path.join(ppmr_path, main_dir)\n",
        "\n",
        "        if os.path.isdir(main_dir_path):\n",
        "            print(f\"Processing main directory: {main_dir_path}\")\n",
        "            for patient_dir in os.listdir(main_dir_path):\n",
        "                patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "                if os.path.isdir(patient_path):\n",
        "                    for sub_dir in os.listdir(patient_path):\n",
        "                        sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                        if os.path.isdir(sub_dir_path):\n",
        "                            for fname in os.listdir(sub_dir_path):\n",
        "                                if fname.endswith(('.jpg', '.png', '.jpeg')):  # Image extensions\n",
        "                                    file_path = os.path.join(sub_dir_path, fname)\n",
        "                                    image_paths.append(file_path)\n",
        "                                    labels.append(label_name)\n",
        "        else:\n",
        "            print(f\"Main directory not found: {main_dir_path}\")\n",
        "else:\n",
        "    print(\"PPMR directory not found.\")\n",
        "\n",
        "# Check if any files were found\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "\n",
        "# Label encoding\n",
        "if image_paths:\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Split dataset into train and test\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    print(f\"Train set: {len(train_paths)}, Test set: {len(test_paths)}\")\n",
        "else:\n",
        "    print(\"No images found. Ensure the directory structure and file extensions are correct.\")\n",
        "\n",
        "# Data Generator for Loading and Preprocessing Images\n",
        "def image_generator(image_paths, labels, batch_size=32, target_size=(224, 224)):\n",
        "    while True:\n",
        "        for start in range(0, len(image_paths), batch_size):\n",
        "            end = min(start + batch_size, len(image_paths))\n",
        "            batch_paths = image_paths[start:end]\n",
        "            batch_labels = labels[start:end]\n",
        "\n",
        "            # Load and preprocess images\n",
        "            images = []\n",
        "            for path in batch_paths:\n",
        "                img = load_img(path, target_size=target_size)\n",
        "                img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "                images.append(img_array)\n",
        "\n",
        "            yield np.array(images), np.array(batch_labels)\n",
        "\n",
        "# Create train and validation generators\n",
        "train_generator = image_generator(train_paths, train_labels, batch_size=32)\n",
        "val_generator = image_generator(test_paths, test_labels, batch_size=32)\n",
        "\n",
        "# Define Model (e.g., ResNet50, MobileNetV2, or EfficientNetB0)\n",
        "def build_model(base_model):\n",
        "    base_model.trainable = False  # Freeze the base model layers\n",
        "\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "\n",
        "    # Add custom CNN layers\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(2, activation='softmax')(x)  # Binary classification (polymicrogyria vs control)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Choose the pre-trained model (ResNet50 as an example)\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Build the model\n",
        "model = build_model(base_model)\n",
        "\n",
        "# Compile the model with recall as a metric\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[Recall()])  # Use Recall instead of Accuracy\n",
        "\n",
        "# Define EarlyStopping callback (patience in terms of epochs)\n",
        "batch_size = 32\n",
        "max_iterations = 4500\n",
        "iterations_per_epoch = len(train_paths) // batch_size\n",
        "epochs_until_stop = max_iterations // iterations_per_epoch\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=epochs_until_stop, restore_best_weights=True)\n",
        "\n",
        "# Train the model with EarlyStopping\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=len(train_paths) // batch_size,  # Steps per epoch\n",
        "    validation_steps=len(test_paths) // batch_size,  # Validation steps\n",
        "    epochs=400,  # Maximum number of epochs\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model using Recall\n",
        "val_loss, val_recall = model.evaluate(val_generator, steps=len(test_paths) // batch_size)\n",
        "print(f\"Validation Recall: {val_recall * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "PfvwFQ6bYDtE",
        "outputId": "6e6166a1-6801-48b5-ef59-7c5db7d27b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing PPMR directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGControlsEditedDec2021\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGstudycaseslabelled\n",
            "Total images found: 15056\n",
            "Train set: 12044, Test set: 3012\n",
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node LogicalAnd defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,32] vs. [1,64]\n\t [[{{node LogicalAnd}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_64414[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_65103]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-803930cf8da5>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Train the model with EarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node LogicalAnd defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,32] vs. [1,64]\n\t [[{{node LogicalAnd}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_64414[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_65103]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5HFQFyesYxfD",
        "outputId": "84af4adb-6a8e-4d84-e1c2-0d4ff2611a59"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No images found. Check dataset structure or file extensions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2980a0036cd6>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Check for images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No images found. Check dataset structure or file extensions.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Step 3: Encode labels and split the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found. Check dataset structure or file extensions."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Step 1: Clone NKUT repository and install dependencies\n",
        "os.system(\"git clone https://github.com/nkicsl/NKUT\")\n",
        "os.chdir(\"NKUT\")\n",
        "os.system(\"pip install -r requirements.txt\")\n",
        "\n",
        "# Step 2: Define dataset paths and preprocessing\n",
        "base_path = \"/path/to/PPMR\"  # Update this with the path to your PPMR dataset\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Mapping for directories in PPMR\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"\n",
        "}\n",
        "\n",
        "# Collect image paths and labels\n",
        "for main_dir, label_name in main_dir_labels.items():\n",
        "    main_dir_path = os.path.join(base_path, main_dir)\n",
        "\n",
        "    if os.path.isdir(main_dir_path):\n",
        "        for patient_dir in os.listdir(main_dir_path):\n",
        "            patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "            if os.path.isdir(patient_path):\n",
        "                for sub_dir in os.listdir(patient_path):\n",
        "                    sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                    if os.path.isdir(sub_dir_path):\n",
        "                        for fname in os.listdir(sub_dir_path):\n",
        "                            if fname.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                                image_paths.append(os.path.join(sub_dir_path, fname))\n",
        "                                labels.append(label_name)\n",
        "\n",
        "# Check for images\n",
        "if not image_paths:\n",
        "    raise ValueError(\"No images found. Check dataset structure or file extensions.\")\n",
        "\n",
        "# Step 3: Encode labels and split the dataset\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Define dataset class\n",
        "class PPMRDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Step 5: Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Step 6: Create DataLoaders\n",
        "train_dataset = PPMRDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PPMRDataset(test_paths, test_labels, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 7: Integrate DataLoaders into NKUT framework\n",
        "# Import and integrate with NKUT model training script\n",
        "import nkut  # Replace with actual NKUT training script/module if applicable\n",
        "\n",
        "model = nkut.NKUTModel()  # Placeholder for NKUT model initialization\n",
        "model.train(train_loader, test_loader)  # Adjust with actual NKUT training functions\n",
        "\n",
        "# Step 8: Verify the pipeline\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcZWh9V_eXR8",
        "outputId": "23fd8ada-4f58-4b88-e257-948b2c565fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No images found in the directory: /path/to/PPMR\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Base directory of the dataset\n",
        "base_path = \"/path/to/PPMR\"  # Replace this with the actual path to your PPMR dataset\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Mapping main directories to labels\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"\n",
        "}\n",
        "\n",
        "# Collecting image paths and labels\n",
        "for main_dir, label_name in main_dir_labels.items():\n",
        "    main_dir_path = os.path.join(base_path, main_dir)\n",
        "\n",
        "    if os.path.isdir(main_dir_path):\n",
        "        for patient_dir in os.listdir(main_dir_path):\n",
        "            patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "            if os.path.isdir(patient_path):\n",
        "                for sub_dir in os.listdir(patient_path):\n",
        "                    sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                    if os.path.isdir(sub_dir_path):\n",
        "                        for file_name in os.listdir(sub_dir_path):\n",
        "                            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                                image_paths.append(os.path.join(sub_dir_path, file_name))\n",
        "                                labels.append(label_name)\n",
        "\n",
        "# Check for images\n",
        "if not image_paths:\n",
        "    print(f\"No images found in the directory: {base_path}\")\n",
        "else:\n",
        "    print(f\"Found {len(image_paths)} images.\")\n",
        "    print(f\"Sample image: {image_paths[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "5YFG73AyetVq",
        "outputId": "1423933b-154d-4124-f96e-1718839ebdb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory not found: /path/to/PPMR/PMGControlsEditedDec2021\n",
            "Directory not found: /path/to/PPMR/PMGstudycaseslabelled\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No images found. Check dataset structure or file extensions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2e4f6f02e39c>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Step 4: Check for images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No images found. Check dataset structure or file extensions.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Step 5: Encode labels and split the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found. Check dataset structure or file extensions."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Step 1: Define dataset base path\n",
        "base_path = \"/path/to/PPMR\"  # Replace with the actual root path of your dataset\n",
        "\n",
        "# Step 2: Initialize lists for image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Mapping for directories in PPMR\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"\n",
        "}\n",
        "\n",
        "# Step 3: Collect image paths and labels\n",
        "for main_dir, label_name in main_dir_labels.items():\n",
        "    main_dir_path = os.path.join(base_path, main_dir)\n",
        "\n",
        "    if os.path.isdir(main_dir_path):\n",
        "        for patient_dir in os.listdir(main_dir_path):\n",
        "            patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "            if os.path.isdir(patient_path):\n",
        "                for fname in os.listdir(patient_path):\n",
        "                    if fname.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        file_path = os.path.join(patient_path, fname)\n",
        "                        image_paths.append(file_path)\n",
        "                        labels.append(label_name)\n",
        "    else:\n",
        "        print(f\"Directory not found: {main_dir_path}\")\n",
        "\n",
        "# Step 4: Check for images\n",
        "if not image_paths:\n",
        "    raise ValueError(\"No images found. Check dataset structure or file extensions.\")\n",
        "\n",
        "# Step 5: Encode labels and split the dataset\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 6: Define dataset class\n",
        "class PPMRDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Step 7: Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Step 8: Create DataLoaders\n",
        "train_dataset = PPMRDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PPMRDataset(test_paths, test_labels, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 9: Verify\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "b5ATTEfge52R",
        "outputId": "dd95c24e-7258-4829-fdf6-b9ad63fb4fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing base directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No images found. Ensure the directory structure and file extensions are correct.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4c869cc221da>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Check if any files were found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No images found. Ensure the directory structure and file extensions are correct.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total images found: {len(image_paths)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found. Ensure the directory structure and file extensions are correct."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Define the base path to the dataset\n",
        "base_path = \"/root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2\"  # Update this to the actual path where your dataset resides\n",
        "\n",
        "# Define a mapping for the main directories\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",  # Healthy cases\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"  # PMG cases\n",
        "}\n",
        "\n",
        "# Collect image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Traverse directories and gather image data\n",
        "if os.path.exists(base_path) and os.path.isdir(base_path):\n",
        "    print(f\"Processing base directory: {base_path}\")\n",
        "    for main_dir, label_name in main_dir_labels.items():\n",
        "        main_dir_path = os.path.join(base_path, main_dir)\n",
        "\n",
        "        if os.path.isdir(main_dir_path):\n",
        "            print(f\"Processing main directory: {main_dir_path}\")\n",
        "            for patient_dir in os.listdir(main_dir_path):\n",
        "                patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "                if os.path.isdir(patient_path):\n",
        "                    for sub_dir in os.listdir(patient_path):\n",
        "                        sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                        if os.path.isdir(sub_dir_path):\n",
        "                            for fname in os.listdir(sub_dir_path):\n",
        "                                if fname.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                                    file_path = os.path.join(sub_dir_path, fname)\n",
        "                                    image_paths.append(file_path)\n",
        "                                    labels.append(label_name)\n",
        "else:\n",
        "    print(f\"Base directory not found or invalid: {base_path}\")\n",
        "\n",
        "# Check if any files were found\n",
        "if not image_paths:\n",
        "    raise ValueError(\"No images found. Ensure the directory structure and file extensions are correct.\")\n",
        "else:\n",
        "    print(f\"Total images found: {len(image_paths)}\")\n",
        "    print(f\"Sample image: {image_paths[0]}\")\n",
        "\n",
        "# Label encoding and dataset splitting\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Train set: {len(train_paths)}, Test set: {len(test_paths)}\")\n",
        "\n",
        "# Define dataset class\n",
        "class PPMRDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = PPMRDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PPMRDataset(test_paths, test_labels, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Print verification information\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
        "\n",
        "# Example of using a batch from train_loader\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "print(f\"Batch size: {images.size(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHYXFWjEfoYn",
        "outputId": "6574ccd4-ae27-441d-afb3-9fbc5349261d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing PPMR directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGControlsEditedDec2021\n",
            "Processing main directory: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGstudycaseslabelled\n",
            "Total images found: 15056\n",
            "Sample image: /root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2/PPMR/PMGControlsEditedDec2021/4/4control2/4control2_cor_0_111.jpg\n",
            "Train set: 12044, Test set: 3012\n",
            "Number of training samples: 12044\n",
            "Number of testing samples: 3012\n",
            "Batch size: 32\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Updated base path from your code\n",
        "base_path = '/root/.cache/kagglehub/datasets/lingfengzhang/pediatric-polymicrogyria-mri-dataset/versions/2'\n",
        "ppmr_path = os.path.join(base_path, 'PPMR')\n",
        "\n",
        "# Define a mapping for the main directories\n",
        "main_dir_labels = {\n",
        "    \"PMGControlsEditedDec2021\": \"control\",  # Healthy cases\n",
        "    \"PMGstudycaseslabelled\": \"polymicrogyria\"  # PMG cases\n",
        "}\n",
        "\n",
        "# Collect image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Traverse directories and gather image data\n",
        "if os.path.exists(ppmr_path) and os.path.isdir(ppmr_path):\n",
        "    print(f\"Processing PPMR directory: {ppmr_path}\")\n",
        "    for main_dir, label_name in main_dir_labels.items():\n",
        "        main_dir_path = os.path.join(ppmr_path, main_dir)\n",
        "\n",
        "        if os.path.isdir(main_dir_path):\n",
        "            print(f\"Processing main directory: {main_dir_path}\")\n",
        "            for patient_dir in os.listdir(main_dir_path):\n",
        "                patient_path = os.path.join(main_dir_path, patient_dir)\n",
        "\n",
        "                if os.path.isdir(patient_path):\n",
        "                    for sub_dir in os.listdir(patient_path):\n",
        "                        sub_dir_path = os.path.join(patient_path, sub_dir)\n",
        "\n",
        "                        if os.path.isdir(sub_dir_path):\n",
        "                            for fname in os.listdir(sub_dir_path):\n",
        "                                if fname.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                                    file_path = os.path.join(sub_dir_path, fname)\n",
        "                                    image_paths.append(file_path)\n",
        "                                    labels.append(label_name)\n",
        "else:\n",
        "    print(f\"Base directory not found or invalid: {ppmr_path}\")\n",
        "\n",
        "# Check if any files were found\n",
        "if not image_paths:\n",
        "    raise ValueError(\"No images found. Ensure the directory structure and file extensions are correct.\")\n",
        "else:\n",
        "    print(f\"Total images found: {len(image_paths)}\")\n",
        "    print(f\"Sample image: {image_paths[0]}\")\n",
        "\n",
        "# Label encoding and dataset splitting\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, encoded_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Train set: {len(train_paths)}, Test set: {len(test_paths)}\")\n",
        "\n",
        "# Define dataset class\n",
        "class PPMRDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = PPMRDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PPMRDataset(test_paths, test_labels, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Print verification information\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
        "\n",
        "# Example of using a batch from train_loader\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "print(f\"Batch size: {images.size(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        with tqdm(total=len(train_loader), desc=\"Training\") as pbar:\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                correct += torch.sum(preds == labels.data)\n",
        "                total += labels.size(0)\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = correct.double() / total\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Evaluating...\")\n",
        "    with tqdm(total=len(test_loader), desc=\"Evaluation\") as pbar:\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Collect predictions and true labels for recall calculation\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "    loss = running_loss / len(test_loader.dataset)\n",
        "\n",
        "    # Calculate recall using sklearn\n",
        "    recall = recall_score(all_labels, all_preds, average=\"binary\")  # Binary classification\n",
        "    print(f\"Test Loss: {loss:.4f}, Test Recall: {recall:.4f}\")\n",
        "    return loss, recall\n",
        "\n",
        "# Step 4: Train and evaluate the model\n",
        "print(\"Starting training...\")\n",
        "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1)\n",
        "\n",
        "print(\"Evaluating on the test set...\")\n",
        "evaluate_model(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "fLik-ntqy9tA",
        "outputId": "1139723f-0573-4043-fd13-994c36c02d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'criterion' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a9e070ae8d8c>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Step 4: Train and evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on the test set...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfhNZ4MbjIyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe1b3f3-92c1-48aa-b8c6-48b110e543cf"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 170MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 79.5MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training and Evaluating: ResNet50\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 377/377 [14:31<00:00,  2.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1119, Accuracy: 0.9702, Time: 871.19s\n",
            "Evaluating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|██████████| 95/95 [00:38<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 1.5132, Test Recall: 0.5960\n",
            "Model: ResNet50, Recall: 0.5960\n",
            "\n",
            "Training and Evaluating: MobileNetV2\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 377/377 [12:38<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0562, Accuracy: 0.9818, Time: 758.81s\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 95/95 [00:33<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0284, Test Recall: 0.9955\n",
            "Model: MobileNetV2, Recall: 0.9955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models\n",
        "from sklearn.metrics import recall_score\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        with tqdm(total=len(train_loader), desc=\"Training\") as pbar:\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                correct += torch.sum(preds == labels.data)\n",
        "                total += labels.size(0)\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = correct.double() / total\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Evaluating...\")\n",
        "    with tqdm(total=len(test_loader), desc=\"Evaluation\") as pbar:\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Collect predictions and true labels for recall calculation\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "    loss = running_loss / len(test_loader.dataset)\n",
        "\n",
        "    # Calculate recall using sklearn\n",
        "    recall = recall_score(all_labels, all_preds, average=\"binary\")  # Binary classification\n",
        "    print(f\"Test Loss: {loss:.4f}, Test Recall: {recall:.4f}\")\n",
        "    return recall\n",
        "\n",
        "# Initialize models\n",
        "models_to_train = {\n",
        "    \"ResNet50\": models.resnet50(pretrained=True),\n",
        "    \"MobileNetV2\": models.mobilenet_v2(pretrained=True)\n",
        "}\n",
        "\n",
        "# Adjust final layers for binary classification\n",
        "for model_name, model in models_to_train.items():\n",
        "    if hasattr(model, \"fc\"):  # For ResNet\n",
        "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    elif hasattr(model, \"classifier\"):  # For MobileNetV2\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "    models_to_train[model_name] = model.to(device)\n",
        "\n",
        "# Define training parameters\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models_to_train.items():\n",
        "    print(f\"\\nTraining and Evaluating: {model_name}\")\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "    train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs)\n",
        "    recall = evaluate_model(model, test_loader, criterion)\n",
        "    print(f\"Model: {model_name}, Recall: {recall:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models\n",
        "from sklearn.metrics import recall_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize EfficientNet-B0\n",
        "efficientnet_b0 = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# Adjust the final layer for binary classification\n",
        "efficientnet_b0.fc = nn.Linear(efficientnet_b0.fc.in_features, 2)\n",
        "efficientnet_b0 = efficientnet_b0.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(efficientnet_b0.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "# Train the model for 1 epoch\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models\n",
        "from torchvision.models import EfficientNet_B0_Weights\n",
        "from sklearn.metrics import recall_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize EfficientNet-B0 with weights\n",
        "efficientnet_b0 = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Adjust the classifier for binary classification\n",
        "efficientnet_b0.classifier[1] = nn.Linear(efficientnet_b0.classifier[1].in_features, 2)\n",
        "efficientnet_b0 = efficientnet_b0.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(efficientnet_b0.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "# Train the model for 1 epoch\n",
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        with tqdm(total=len(train_loader), desc=\"Training\") as pbar:\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                pbar.update(1)\n",
        "        scheduler.step()\n",
        "\n",
        "# Evaluate the model and calculate recall\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with tqdm(total=len(test_loader), desc=\"Evaluation\") as pbar:\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                pbar.update(1)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    return recall\n",
        "\n",
        "# Train and evaluate EfficientNet-B0\n",
        "train_model(efficientnet_b0, train_loader, criterion, optimizer, scheduler, num_epochs=1)\n",
        "evaluate_model(efficientnet_b0, test_loader, criterion)\n",
        "\n"
      ],
      "metadata": {
        "id": "Eof7gEzyIHIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64c5034-924d-4a91-d2a0-18f6cf59eb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 75.0MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'EfficientNet' object has no attribute 'fc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ed34fedbda16>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Adjust the final layer for binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mefficientnet_b0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_b0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mefficientnet_b0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mefficientnet_b0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'EfficientNet' object has no attribute 'fc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57mWVAjLQ_79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models\n",
        "from torchvision.models import EfficientNet_B0_Weights\n",
        "from sklearn.metrics import recall_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize EfficientNet-B0 with weights\n",
        "efficientnet_b0 = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Adjust the classifier for binary classification\n",
        "efficientnet_b0.classifier[1] = nn.Linear(efficientnet_b0.classifier[1].in_features, 2)\n",
        "efficientnet_b0 = efficientnet_b0.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(efficientnet_b0.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "# Train the model for 1 epoch\n",
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        with tqdm(total=len(train_loader), desc=\"Training\") as pbar:\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                pbar.update(1)\n",
        "        scheduler.step()\n",
        "\n",
        "# Evaluate the model and calculate recall\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with tqdm(total=len(test_loader), desc=\"Evaluation\") as pbar:\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                pbar.update(1)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    return recall\n",
        "\n",
        "# Train and evaluate EfficientNet-B0\n",
        "train_model(efficientnet_b0, train_loader, criterion, optimizer, scheduler, num_epochs=1)\n",
        "evaluate_model(efficientnet_b0, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eve-9EarRYuw",
        "outputId": "dadb3922-c207-4f36-9fca-731ef1f7d46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 377/377 [11:25<00:00,  1.82s/it]\n",
            "Evaluation: 100%|██████████| 95/95 [00:34<00:00,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet50_Weights, MobileNet_V2_Weights, EfficientNet_B0_Weights\n",
        "from sklearn.metrics import recall_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize individual models with pretrained weights\n",
        "resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "mobilenet_v2 = models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "efficientnet_b0 = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Adjust final layers for binary classification\n",
        "resnet50.fc = nn.Linear(resnet50.fc.in_features, 2)\n",
        "mobilenet_v2.classifier[1] = nn.Linear(mobilenet_v2.classifier[1].in_features, 2)\n",
        "efficientnet_b0.classifier[1] = nn.Linear(efficientnet_b0.classifier[1].in_features, 2)\n",
        "\n",
        "# Move models to device\n",
        "resnet50 = resnet50.to(device)\n",
        "mobilenet_v2 = mobilenet_v2.to(device)\n",
        "efficientnet_b0 = efficientnet_b0.to(device)\n",
        "\n",
        "# Define a function to train individual models\n",
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        with tqdm(total=len(train_loader), desc=\"Training\") as pbar:\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                pbar.update(1)\n",
        "        scheduler.step()\n",
        "\n",
        "# Train each model for 1 epoch\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "\n",
        "for model, model_name in zip(\n",
        "    [resnet50, mobilenet_v2, efficientnet_b0], [\"ResNet50\", \"MobileNetV2\", \"EfficientNet-B0\"]\n",
        "):\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "    train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=1)\n",
        "\n",
        "# Define the ensemble function\n",
        "def ensemble_evaluate(models, test_loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"\\nEvaluating Ensemble...\")\n",
        "    with tqdm(total=len(test_loader), desc=\"Ensemble Evaluation\") as pbar:\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Average predictions from all models\n",
        "                outputs = torch.stack([model(inputs) for model in models], dim=0)\n",
        "                avg_outputs = torch.mean(outputs, dim=0)\n",
        "\n",
        "                _, preds = torch.max(avg_outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                pbar.update(1)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
        "    print(f\"Ensemble Recall: {recall:.4f}\")\n",
        "    return recall\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "ensemble_recall = ensemble_evaluate([resnet50, mobilenet_v2, efficientnet_b0], test_loader)\n"
      ],
      "metadata": {
        "id": "zKarsQtmRZWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtPIjxnqUOXh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}